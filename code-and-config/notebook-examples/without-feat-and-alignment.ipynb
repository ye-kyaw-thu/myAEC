{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-23T10:29:14.318Z",
     "iopub.execute_input": "2025-11-23T10:29:13.752009Z",
     "iopub.status.busy": "2025-11-23T10:29:13.751784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/ipa-aec/AEC_IPA.tsv\", sep=\"\\t\")\n",
    "\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "train_df[\"ASR_Error\"].to_csv(\"/kaggle/working/err_syl.train\", index=False, header=False)\n",
    "train_df[\"Correct\"].to_csv(\"/kaggle/working/crr_syl.train\", index=False, header=False)\n",
    "\n",
    "val_df[\"ASR_Error\"].to_csv(\"/kaggle/working/err_syl.val\", index=False, header=False)\n",
    "val_df[\"Correct\"].to_csv(\"/kaggle/working/crr_syl.val\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-23T10:29:14.319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:30:12.766911Z",
     "iopub.status.busy": "2025-09-09T08:30:12.766656Z",
     "iopub.status.idle": "2025-09-09T08:32:48.494470Z",
     "shell.execute_reply": "2025-09-09T08:32:48.493545Z",
     "shell.execute_reply.started": "2025-09-09T08:30:12.766893Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting OpenNMT-py\n",
      "  Downloading OpenNMT_py-3.5.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting torch<2.3,>=2.1 (from OpenNMT-py)\n",
      "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting configargparse (from OpenNMT-py)\n",
      "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting ctranslate2<5,>=4 (from OpenNMT-py)\n",
      "  Downloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (2.18.0)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.1.1)\n",
      "Collecting waitress (from OpenNMT-py)\n",
      "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pyonmttok<2,>=1.37 (from OpenNMT-py)\n",
      "  Downloading pyonmttok-1.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (6.0.2)\n",
      "Collecting sacrebleu (from OpenNMT-py)\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n",
      "  Downloading rapidfuzz-3.14.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Collecting pyahocorasick (from OpenNMT-py)\n",
      "  Downloading pyahocorasick-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting fasttext-wheel (from OpenNMT-py)\n",
      "  Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.8.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4->OpenNMT-py) (75.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4->OpenNMT-py) (1.26.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.73.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.8.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (4.14.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch<2.3,>=2.1->OpenNMT-py)\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->OpenNMT-py) (12.5.82)\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel->OpenNMT-py) (2.13.6)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (3.0.2)\n",
      "Collecting portalocker (from sacrebleu->OpenNMT-py)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (5.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.11.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->OpenNMT-py) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4->OpenNMT-py) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4->OpenNMT-py) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4->OpenNMT-py) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4->OpenNMT-py) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4->OpenNMT-py) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4->OpenNMT-py) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2025.6.15)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->OpenNMT-py) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->OpenNMT-py) (0.1.5)\n",
      "Collecting numpy (from ctranslate2<5,>=4->OpenNMT-py)\n",
      "  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (7.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->OpenNMT-py) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->OpenNMT-py) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (2.19.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (0.1.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ctranslate2<5,>=4->OpenNMT-py) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ctranslate2<5,>=4->OpenNMT-py) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->ctranslate2<5,>=4->OpenNMT-py) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->ctranslate2<5,>=4->OpenNMT-py) (2024.2.0)\n",
      "INFO: pip is looking at multiple versions of mkl-fft to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mkl_fft (from numpy->ctranslate2<5,>=4->OpenNMT-py)\n",
      "  Downloading mkl_fft-2.0.0-22-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.1 kB)\n",
      "Collecting numpy (from ctranslate2<5,>=4->OpenNMT-py)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of mkl-random to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mkl_random (from numpy->ctranslate2<5,>=4->OpenNMT-py)\n",
      "  Downloading mkl_random-1.2.11-22-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "INFO: pip is looking at multiple versions of mkl-umath to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mkl_umath (from numpy->ctranslate2<5,>=4->OpenNMT-py)\n",
      "  Downloading mkl_umath-0.2.0-21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->ctranslate2<5,>=4->OpenNMT-py) (2024.2.0)\n",
      "Downloading OpenNMT_py-3.5.1-py3-none-any.whl (262 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.8/262.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyonmttok-1.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
      "Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyahocorasick-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.14.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: waitress, triton, rapidfuzz, pyonmttok, pyahocorasick, portalocker, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, configargparse, sacrebleu, nvidia-cusolver-cu12, nvidia-cudnn-cu12, fasttext-wheel, ctranslate2, torch, OpenNMT-py\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu124\n",
      "    Uninstalling torch-2.6.0+cu124:\n",
      "      Successfully uninstalled torch-2.6.0+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
      "ydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "pandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed OpenNMT-py-3.5.1 configargparse-1.7.1 ctranslate2-4.6.0 fasttext-wheel-0.9.2 numpy-2.2.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 portalocker-3.2.0 pyahocorasick-2.2.0 pyonmttok-1.37.1 rapidfuzz-3.14.1 sacrebleu-2.5.1 torch-2.2.2 triton-2.2.0 waitress-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install OpenNMT-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:32:48.496517Z",
     "iopub.status.busy": "2025-09-09T08:32:48.496119Z",
     "iopub.status.idle": "2025-09-09T08:32:55.029905Z",
     "shell.execute_reply": "2025-09-09T08:32:55.029155Z",
     "shell.execute_reply.started": "2025-09-09T08:32:48.496468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "pandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T10:29:55.713457Z",
     "iopub.status.busy": "2025-11-23T10:29:55.713226Z",
     "iopub.status.idle": "2025-11-23T10:30:05.432889Z",
     "shell.execute_reply": "2025-11-23T10:30:05.430727Z",
     "shell.execute_reply.started": "2025-11-23T10:29:55.713435Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libunwind-dev\n",
      "The following NEW packages will be installed:\n",
      "  libgoogle-perftools-dev libsparsehash-dev libunwind-dev\n",
      "0 upgraded, 3 newly installed, 0 to remove and 38 not upgraded.\n",
      "Need to get 2,424 kB of archives.\n",
      "After this operation, 10.4 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libunwind-dev amd64 1.3.2-2build2.1 [1,883 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgoogle-perftools-dev amd64 2.9.1-0ubuntu3 [470 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsparsehash-dev all 2.0.3-2 [71.7 kB]\n",
      "Fetched 2,424 kB in 1s (2,072 kB/s)          \n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Selecting previously unselected package libunwind-dev:amd64.\n",
      "(Reading database ... 128663 files and directories currently installed.)\n",
      "Preparing to unpack .../libunwind-dev_1.3.2-2build2.1_amd64.deb ...\n",
      "Unpacking libunwind-dev:amd64 (1.3.2-2build2.1) ...\n",
      "Selecting previously unselected package libgoogle-perftools-dev:amd64.\n",
      "Preparing to unpack .../libgoogle-perftools-dev_2.9.1-0ubuntu3_amd64.deb ...\n",
      "Unpacking libgoogle-perftools-dev:amd64 (2.9.1-0ubuntu3) ...\n",
      "Selecting previously unselected package libsparsehash-dev.\n",
      "Preparing to unpack .../libsparsehash-dev_2.0.3-2_all.deb ...\n",
      "Unpacking libsparsehash-dev (2.0.3-2) ...\n",
      "Setting up libunwind-dev:amd64 (1.3.2-2build2.1) ...\n",
      "Setting up libgoogle-perftools-dev:amd64 (2.9.1-0ubuntu3) ...\n",
      "Setting up libsparsehash-dev (2.0.3-2) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install libgoogle-perftools-dev libsparsehash-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T10:30:05.435677Z",
     "iopub.status.busy": "2025-11-23T10:30:05.435289Z",
     "iopub.status.idle": "2025-11-23T10:30:14.227933Z",
     "shell.execute_reply": "2025-11-23T10:30:14.227210Z",
     "shell.execute_reply.started": "2025-11-23T10:30:05.435647Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fast_align'...\n",
      "remote: Enumerating objects: 213, done.\u001b[K\n",
      "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 213 (delta 32), reused 26 (delta 26), pack-reused 172 (from 1)\u001b[K\n",
      "Receiving objects: 100% (213/213), 62.05 KiB | 1.44 MiB/s, done.\n",
      "Resolving deltas: 100% (115/115), done.\n",
      "/kaggle/working/fast_align/build\n",
      "\u001b[33mCMake Warning (dev) at CMakeLists.txt:1 (project):\n",
      "  cmake_minimum_required() should be called prior to this top-level project()\n",
      "  call.  Please see the cmake-commands(7) manual for usage documentation of\n",
      "  both commands.\n",
      "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[0m\n",
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:2 (cmake_minimum_required):\n",
      "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "  CMake.\n",
      "\n",
      "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "  to tell CMake that the project requires at least <min> but has been updated\n",
      "  to work with policies introduced by <max> or earlier.\n",
      "\n",
      "\u001b[0m\n",
      "-- Found SparseHash: /usr/include\n",
      "-- Configuring done (1.8s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /kaggle/working/fast_align/build\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/fast_align.dir/src/fast_align.cc.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/fast_align.dir/src/ttables.cc.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/atools.dir/src/alignment_io.cc.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/atools.dir/src/atools.cc.o\u001b[0m\n",
      "[ 83%] \u001b[32m\u001b[1mLinking CXX executable atools\u001b[0m\n",
      "[ 83%] Built target atools\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable fast_align\u001b[0m\n",
      "[100%] Built target fast_align\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/clab/fast_align.git\n",
    "\n",
    "!mkdir fast_align/build\n",
    "%cd fast_align/build\n",
    "!cmake ..\n",
    "!make -j4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T10:36:05.562021Z",
     "iopub.status.busy": "2025-11-23T10:36:05.561748Z",
     "iopub.status.idle": "2025-11-23T10:36:48.822234Z",
     "shell.execute_reply": "2025-11-23T10:36:48.821074Z",
     "shell.execute_reply.started": "2025-11-23T10:36:05.562002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARG=i\n",
      "ARG=d\n",
      "ARG=o\n",
      "ARG=v\n",
      "INITIAL PASS \n",
      ".................................................. [50000]\n",
      ".....\n",
      "expected target length = source length * 1.08165\n",
      "ITERATION 1\n",
      ".................................................. [50000]\n",
      ".....\n",
      "  log_e likelihood: -4.54874e+07\n",
      "  log_2 likelihood: -6.56245e+07\n",
      "     cross entropy: 29.8974\n",
      "        perplexity: 1e+09\n",
      "      posterior p0: 0.08\n",
      " posterior al-feat: -0.164094\n",
      "       size counts: 4968\n",
      "ITERATION 2\n",
      ".................................................. [50000]\n",
      ".....\n",
      "  log_e likelihood: -1.15927e+07\n",
      "  log_2 likelihood: -1.67247e+07\n",
      "     cross entropy: 7.61948\n",
      "        perplexity: 196.649\n",
      "      posterior p0: 0.0550713\n",
      " posterior al-feat: -0.122326\n",
      "       size counts: 4968\n",
      "  1  model al-feat: -0.170517 (tension=4)\n",
      "  2  model al-feat: -0.148852 (tension=4.96383)\n",
      "  3  model al-feat: -0.138747 (tension=5.49435)\n",
      "  4  model al-feat: -0.133054 (tension=5.82277)\n",
      "  5  model al-feat: -0.129548 (tension=6.03734)\n",
      "  6  model al-feat: -0.127277 (tension=6.18178)\n",
      "  7  model al-feat: -0.12576 (tension=6.28081)\n",
      "  8  model al-feat: -0.124727 (tension=6.3495)\n",
      "     final tension: 6.39751\n",
      "ITERATION 3\n",
      ".................................................. [50000]\n",
      ".....\n",
      "  log_e likelihood: -9.37048e+06\n",
      "  log_2 likelihood: -1.35187e+07\n",
      "     cross entropy: 6.1589\n",
      "        perplexity: 71.4518\n",
      "      posterior p0: 0.0442146\n",
      " posterior al-feat: -0.0792089\n",
      "       size counts: 4968\n",
      "  1  model al-feat: -0.124013 (tension=6.39751)\n",
      "  2  model al-feat: -0.111923 (tension=7.29359)\n",
      "  3  model al-feat: -0.104377 (tension=7.94786)\n",
      "  4  model al-feat: -0.099187 (tension=8.45123)\n",
      "  5  model al-feat: -0.0953994 (tension=8.85079)\n",
      "  6  model al-feat: -0.0925244 (tension=9.1746)\n",
      "  7  model al-feat: -0.0902799 (tension=9.44091)\n",
      "  8  model al-feat: -0.0884908 (tension=9.66233)\n",
      "     final tension: 9.84797\n",
      "ITERATION 4\n",
      ".................................................. [50000]\n",
      ".....\n",
      "  log_e likelihood: -8.43694e+06\n",
      "  log_2 likelihood: -1.21719e+07\n",
      "     cross entropy: 5.54532\n",
      "        perplexity: 46.6989\n",
      "      posterior p0: 0.0497361\n",
      " posterior al-feat: -0.0606245\n",
      "       size counts: 4968\n",
      "  1  model al-feat: -0.087042 (tension=9.84797)\n",
      "  2  model al-feat: -0.0831552 (tension=10.3763)\n",
      "  3  model al-feat: -0.0800929 (tension=10.8269)\n",
      "  4  model al-feat: -0.0776154 (tension=11.2163)\n",
      "  5  model al-feat: -0.0755701 (tension=11.5561)\n",
      "  6  model al-feat: -0.0738545 (tension=11.855)\n",
      "  7  model al-feat: -0.0723969 (tension=12.1196)\n",
      "  8  model al-feat: -0.0711455 (tension=12.3551)\n",
      "     final tension: 12.5655\n",
      "ITERATION 5 (FINAL)\n",
      ".................................................. [50000]\n",
      ".....\n",
      "  log_e likelihood: -8.06934e+06\n",
      "  log_2 likelihood: -1.16416e+07\n",
      "     cross entropy: 5.30371\n",
      "        perplexity: 39.498\n",
      "      posterior p0: 0\n",
      " posterior al-feat: 0\n",
      "       size counts: 4968\n"
     ]
    }
   ],
   "source": [
    "!/kaggle/working/fast_align/build/fast_align \\\n",
    "    -i /kaggle/input/synde-aec/Aug_Without_Feat.tsv \\\n",
    "    -d -o -v > /kaggle/working/synde_without_feat_1.align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:33:30.432756Z",
     "iopub.status.busy": "2025-09-09T08:33:30.432496Z",
     "iopub.status.idle": "2025-09-09T08:33:30.557968Z",
     "shell.execute_reply": "2025-09-09T08:33:30.557186Z",
     "shell.execute_reply.started": "2025-09-09T08:33:30.432730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# mm_spell_t.yaml\n",
      "\n",
      "save_data: /kaggle/working/transformer\n",
      "overwrite: True\n",
      "\n",
      "src_vocab: /kaggle/working/transformer/mm_spell.vocab.src\n",
      "tgt_vocab: /kaggle/working/transformer/mm_spell.vocab.tgt\n",
      "vocab_size_multiple: 8\n",
      "src_words_min_frequency: 1\n",
      "tgt_words_min_frequency: 1\n",
      "share_vocab: True\n",
      "n_sample: 0\n",
      "\n",
      "src_seq_length: 200\n",
      "tgt_seq_length: 200\n",
      "\n",
      "data:\n",
      "   corpus_1:\n",
      "       path_src: /kaggle/working/err_syl.train\n",
      "       path_tgt: /kaggle/working/crr_syl.train\n",
      "       path_align: /kaggle/working/forward1.align\n",
      "   valid:\n",
      "       path_src: /kaggle/working/err_syl.val\n",
      "       path_tgt: /kaggle/working/crr_syl.val\n",
      "\n",
      "save_model: ./transformer/working/model/transformer.mmspell\n",
      "save_checkpoint_steps: 10000\n",
      "keep_checkpoint: 10\n",
      "average_decay: 0\n",
      "seed: 3435\n",
      "train_steps: 200000\n",
      "valid_steps: 10000\n",
      "warmup_steps: 5000\n",
      "report_every: 1000\n",
      "early_stopping: 4\n",
      "\n",
      "\n",
      "decoder_type: transformer\n",
      "encoder_type: transformer\n",
      "word_vec_size: 512\n",
      "hidden_size: 512\n",
      "enc_layers: 6\n",
      "dec_layers: 6\n",
      "transformer_ff: 2048\n",
      "heads: 8\n",
      "full_context_alignment: true\n",
      "lambda_algin: 0.06\n",
      "alignment_layer: 4\n",
      "alignment_heads: 8\n",
      "accum_count: 4\n",
      "\n",
      "model_dtype: \"fp16\"\n",
      "optim: adam\n",
      "adam_beta1: 0.9\n",
      "adam_beta2: 0.998\n",
      "decay_method: noam\n",
      "learning_rate: 0.1\n",
      "max_grad_norm: 0.0\n",
      "\n",
      "batch_size: 64\n",
      "batch_type: tokens\n",
      "normalization: tokens\n",
      "dropout_steps: [0]\n",
      "dropout: [0.3]\n",
      "attention_dropout: [0.3]\n",
      "position_encoding: true\n",
      "label_smoothing: 0.1\n",
      "\n",
      "max_generator_batches: 2\n",
      "\n",
      "param_init: 0.0\n",
      "param_init_glorot: true\n",
      "\n",
      "world_size: 1\n",
      "gpu_ranks: [0]\n",
      "\n",
      "tensorboard: true\n",
      "tensorboard_log_dir: ./transformer/logs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Create the YAML configuration file\n",
    "# On a regular machine, you can create it manually or with nano\n",
    "\n",
    "config = '''\n",
    "\n",
    "# mm_spell_t.yaml\n",
    "\n",
    "save_data: /kaggle/working/transformer\n",
    "overwrite: True\n",
    "\n",
    "src_vocab: /kaggle/working/transformer/mm_spell.vocab.src\n",
    "tgt_vocab: /kaggle/working/transformer/mm_spell.vocab.tgt\n",
    "vocab_size_multiple: 8\n",
    "src_words_min_frequency: 1\n",
    "tgt_words_min_frequency: 1\n",
    "share_vocab: True\n",
    "n_sample: 0\n",
    "\n",
    "src_seq_length: 200\n",
    "tgt_seq_length: 200\n",
    "\n",
    "data:\n",
    "    corpus_1:\n",
    "        path_src: /kaggle/working/err_syl.train\n",
    "        path_tgt: /kaggle/working/crr_syl.train\n",
    "        path_align: /kaggle/working/forward1.align\n",
    "    valid:\n",
    "        path_src: /kaggle/working/err_syl.val\n",
    "        path_tgt: /kaggle/working/crr_syl.val\n",
    "\n",
    "save_model: ./transformer/working/model/transformer.mmspell\n",
    "save_checkpoint_steps: 10000\n",
    "keep_checkpoint: 10\n",
    "average_decay: 0\n",
    "seed: 3435\n",
    "train_steps: 200000\n",
    "valid_steps: 10000\n",
    "warmup_steps: 5000\n",
    "report_every: 1000\n",
    "early_stopping: 4\n",
    "\n",
    "\n",
    "decoder_type: transformer\n",
    "encoder_type: transformer\n",
    "word_vec_size: 512\n",
    "hidden_size: 512\n",
    "enc_layers: 4\n",
    "dec_layers: 4\n",
    "transformer_ff: 2048\n",
    "heads: 8\n",
    "accum_count: 4\n",
    "\n",
    "model_dtype: \"fp16\"\n",
    "optim: adam\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.998\n",
    "decay_method: noam\n",
    "learning_rate: 0.1\n",
    "max_grad_norm: 0.0\n",
    "\n",
    "batch_size: 64\n",
    "batch_type: tokens\n",
    "normalization: tokens\n",
    "dropout_steps: [0]\n",
    "dropout: [0.3]\n",
    "attention_dropout: [0.3]\n",
    "position_encoding: true\n",
    "label_smoothing: 0.1\n",
    "\n",
    "max_generator_batches: 2\n",
    "\n",
    "param_init: 0.0\n",
    "param_init_glorot: true\n",
    "\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "tensorboard: true\n",
    "tensorboard_log_dir: ./transformer/logs\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "with open(\"mm_spell_t.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)\n",
    "\n",
    "# full_context_alignment: true\n",
    "# lambda_algin: 0.06\n",
    "# alignment_layer: 4\n",
    "# alignment_heads: 8\n",
    "\n",
    "!cat mm_spell_t.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:33:30.560538Z",
     "iopub.status.busy": "2025-09-09T08:33:30.560307Z",
     "iopub.status.idle": "2025-09-09T08:33:38.249985Z",
     "shell.execute_reply": "2025-09-09T08:33:38.249241Z",
     "shell.execute_reply.started": "2025-09-09T08:33:30.560515Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-09 08:33:35,947 INFO] Counter vocab from -1 samples.\n",
      "[2025-09-09 08:33:35,947 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2025-09-09 08:33:37,401 INFO] Counters src: 10948\n",
      "[2025-09-09 08:33:37,401 INFO] Counters tgt: 2349\n",
      "[2025-09-09 08:33:37,403 INFO] Counters after share:11029\n"
     ]
    }
   ],
   "source": [
    "!onmt_build_vocab -config mm_spell_t.yaml -n_sample -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:33:38.251244Z",
     "iopub.status.busy": "2025-09-09T08:33:38.251010Z",
     "iopub.status.idle": "2025-09-09T08:33:38.266261Z",
     "shell.execute_reply": "2025-09-09T08:33:38.265526Z",
     "shell.execute_reply.started": "2025-09-09T08:33:38.251221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_path = \"/kaggle/working/transformer/mm_spell.vocab.src\"\n",
    "\n",
    "with open(vocab_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(vocab_path, \"w\") as f:\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 2 and parts[1].isdigit():\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:33:38.267329Z",
     "iopub.status.busy": "2025-09-09T08:33:38.267147Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-09 08:33:43,022 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
      "[2025-09-09 08:33:43,022 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2025-09-09 08:33:43,022 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2025-09-09 08:33:43,022 INFO] Parsed 2 corpora from -data.\n",
      "[2025-09-09 08:33:43,022 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2025-09-09 08:33:43,046 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'အ', 'သည်', 'များ', 'ကို', 'င့်', 'ပါ']\n",
      "[2025-09-09 08:33:43,046 INFO] The decoder start token is: <s>\n",
      "[2025-09-09 08:33:43,046 INFO] Building model...\n",
      "[2025-09-09 08:33:44,164 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2025-09-09 08:33:44,164 INFO] Non quantized layer compute is fp16\n",
      "[2025-09-09 08:33:44,372 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(11032, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.3, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(11032, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0-5): 6 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.3, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=11032, bias=True)\n",
      ")\n",
      "[2025-09-09 08:33:44,374 INFO] encoder: 24536064\n",
      "[2025-09-09 08:33:44,374 INFO] decoder: 36493080\n",
      "[2025-09-09 08:33:44,374 INFO] * number of parameters: 61029144\n",
      "[2025-09-09 08:33:44,375 INFO] Trainable parameters = {'torch.float32': 61029144, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2025-09-09 08:33:44,376 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2025-09-09 08:33:44,376 INFO]  * src vocab size = 11032\n",
      "[2025-09-09 08:33:44,376 INFO]  * tgt vocab size = 11032\n",
      "2025-09-09 08:33:48.173620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757406828.359899     380 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757406828.415130     380 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "[2025-09-09 08:34:00,481 INFO] Starting training on GPU: [0]\n",
      "[2025-09-09 08:34:00,481 INFO] Start training loop and validate every 10000 steps...\n",
      "[2025-09-09 08:34:00,482 INFO] Scoring with: None\n",
      "[2025-09-09 08:34:04,326 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2025-09-09 08:34:07,974 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2025-09-09 08:34:08,616 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2025-09-09 08:34:08,717 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2025-09-09 08:34:09,539 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2025-09-09 08:34:09,654 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2025-09-09 08:34:10,589 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2025-09-09 08:34:10,706 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2025-09-09 08:34:11,726 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2025-09-09 08:34:11,860 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2025-09-09 08:34:12,453 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2025-09-09 08:34:12,652 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2025-09-09 08:34:13,798 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2025-09-09 08:34:14,019 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2025-09-09 08:34:14,578 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2025-09-09 08:34:14,824 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2025-09-09 08:34:16,029 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2025-09-09 08:34:16,348 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2025-09-09 08:34:16,758 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2025-09-09 08:34:17,142 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2025-09-09 08:34:18,417 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2025-09-09 08:34:18,877 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2025-09-09 08:34:19,165 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2025-09-09 08:34:19,724 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2025-09-09 08:34:19,912 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2025-09-09 08:34:20,543 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2025-09-09 08:34:21,827 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2025-09-09 08:34:22,540 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2025-09-09 08:34:22,543 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2025-09-09 08:34:23,286 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2025-09-09 08:34:23,380 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2025-09-09 08:34:24,079 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2025-09-09 08:34:24,239 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2025-09-09 08:34:25,011 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2025-09-09 08:34:26,324 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2025-09-09 08:34:27,067 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2025-09-09 08:34:27,299 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2025-09-09 08:34:27,804 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2025-09-09 08:34:28,130 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2025-09-09 08:34:28,595 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2025-09-09 08:34:28,977 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2025-09-09 08:34:29,339 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2025-09-09 08:34:29,773 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2025-09-09 08:34:30,563 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config mm_spell_t.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-05T07:08:18.426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_dir = \"./transformer/working/model/\"\n",
    "checkpoints = [f for f in os.listdir(model_dir) if f.endswith(\".pt\")]\n",
    "latest_checkpoint = sorted(checkpoints)[-1] \n",
    "latest_model_path = os.path.join(model_dir, latest_checkpoint)\n",
    "\n",
    "print(\"Using model:\", latest_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import HfApi, upload_file\n",
    "\n",
    "model_dir = \"./transformer/working/model/\"\n",
    "\n",
    "checkpoints = [f for f in os.listdir(model_dir) if f.endswith(\".pt\")]\n",
    "checkpoints = sorted(checkpoints)\n",
    "\n",
    "print(f\"Found {len(checkpoints)} checkpoints: {checkpoints}\")\n",
    "\n",
    "repo_id = \"LULab/whisper-align-chn-checkpoints-alignment\"\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id, repo_type=\"model\", exist_ok=True)\n",
    "\n",
    "for ckpt in checkpoints:\n",
    "    ckpt_path = os.path.join(model_dir, ckpt)\n",
    "    print(f\"Uploading {ckpt_path}...\")\n",
    "    upload_file(\n",
    "        path_or_fileobj=ckpt_path,\n",
    "        path_in_repo=f\"checkpoints/{ckpt}\",  \n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"model\"\n",
    "    )\n",
    "\n",
    "print(\"All checkpoints uploaded.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8117691,
     "sourceId": 12835407,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8123836,
     "sourceId": 12844520,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8812866,
     "sourceId": 13837431,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8812888,
     "sourceId": 13837462,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
